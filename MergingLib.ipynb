{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### @brief method that merges two .csv files horizontally based on the identifiers\n",
    "#   of a given column \n",
    "#   @param[in] icsv1 the first imported .csv file to be merged horizontally\n",
    "#   @param[in] icsv2 the second imported .csv file to be merged horizontally\n",
    "#   @param[in] ocsv the output csv file\n",
    "#  @param[in] samplingSizeFile. This is also found in the same location as the \n",
    "#  .ipynb files of the PlotToSat. It contains a number that shows how many plot \n",
    "#  data were interpeted per each exported .csv file. Please note that .csv \n",
    "#  file may have less lines due to missing or masked out data\n",
    "#def mergeHorizontally(icsv1, icsv2, ocsv,samplingSizeFile):\n",
    "#    df1 = pd.read_csv(icsv1)\n",
    "#    df2 = pd.read_csv(icsv2)\n",
    "\n",
    "#    mergedDF = pd.merge(df1, df2,on=\"indexField\",how='outer')\n",
    "\n",
    "#    mergedDF.to_csv(ocsv, index=False)\n",
    "\n",
    "    \n",
    "## @brief method that merges all the exported data from PlotToSat into \n",
    "#  a single .csv file\n",
    "#  @notes it assumes that all processes finished smoothly\n",
    "#  @param[in] nameOfCSVFolderDir the directory that contains all the exported\n",
    "#  .csv files. You need to download and extract this folder from Google Drive\n",
    "#  @param[in] fieldDataWithIdentifiers after each run, this is found at the \n",
    "#  same directory as PlotToSat .ipynb files. It is the field data with an extra\n",
    "#  column named \"indexField\". This column saves some identifiers used to merge\n",
    "#  the field data with the exported EO spectral temporal signatures\n",
    "#  @param[in] samplingSizeFile. This is also found in the same location as the \n",
    "#  .ipynb files of the PlotToSat. It contains a number that shows how many plot \n",
    "#  data were interpeted per each exported .csv file. Please note that .csv \n",
    "#  file may have less lines due to missing or masked out data\n",
    "def mergeAll(nameOfCSVFolderDir,fieldDataWithIdentifiers,samplingSizeFile):\n",
    "    \n",
    "    fieldDataDir       =fieldDataWithIdentifiers\n",
    "    samplingSize = 400\n",
    "\n",
    "    # make tmp directories\n",
    "    TmpDir = os.path.join(nameOfCSVFolderDir,\"TmpDir\")\n",
    "    ResDir  = os.path.join(nameOfCSVFolderDir,\"MergedCsvs\")\n",
    "    if os.path.isdir(TmpDir):\n",
    "        print (\"TmpDir Exist\")\n",
    "        shutil.rmtree(TmpDir)\n",
    "    os.mkdir(TmpDir)\n",
    "    if os.path.isdir(ResDir):\n",
    "        print (\"MergedCsvs Exist\")\n",
    "        shutil.rmtree(ResDir)\n",
    "    os.mkdir(ResDir)\n",
    "\n",
    "    # Read sampling rate\n",
    "    try:\n",
    "        f = open(samplingSizeFile,\"r\")\n",
    "        s = f.readline()\n",
    "        print (s , \"************************\")\n",
    "        samplingSize = int(s)\n",
    "        f.close()\n",
    "    except OSError:\n",
    "        print(\"ERROR:\", samplingSizeFile,\" does not exist. Setting sampling size to default = 400\")\n",
    "        samplingSize = 400\n",
    "\n",
    "\n",
    "        \n",
    "    ListS1Mean=[]\n",
    "    ListS2Mean=[]\n",
    "    ListS1StdD=[]\n",
    "    ListS2StdD=[]\n",
    "\n",
    "    for file1 in glob.glob(nameOfCSVFolderDir+\"/*.csv\"):\n",
    "        S1Mean=\"S1_mean.csv\"\n",
    "        S2Mean=\"S2_mean.csv\"\n",
    "        S1StdD=\"S1_stdD.csv\"\n",
    "        S2StdD=\"S2_stdD.csv\"\n",
    "        if(len(file1)>11):\n",
    "            if   (file1[len(file1)-11:len(file1)]==S1Mean):\n",
    "                ListS1Mean=ListS1Mean+[file1]\n",
    "            elif (file1[len(file1)-11:len(file1)]==S2Mean):\n",
    "                ListS2Mean=ListS2Mean+[file1]\n",
    "            elif (file1[len(file1)-11:len(file1)]==S1StdD):\n",
    "                ListS1StdD=ListS1StdD+[file1]\n",
    "            elif (file1[len(file1)-11:len(file1)]==S2StdD):\n",
    "                ListS2StdD=ListS2StdD+[file1]\n",
    "            elif (file1[len(file1)-11:len(file1)]==\"tifiers.csv\"): #in case field data are added in the nameOfCSVFolderDir\n",
    "                print(file1 , \" is suspected to be the field data file\")\n",
    "            else :\n",
    "                print(\"WARNING: \", file1, \" is ignored since it is not recognised as an output of the system\")\n",
    "\n",
    "        #df = pd.read_csv(file)\n",
    "        #df = df.reindex(sorted(df.columns),axis=1)\n",
    "\n",
    "    ListS1Mean.sort()\n",
    "    ListS1StdD.sort()\n",
    "    ListS2Mean.sort()\n",
    "    ListS2StdD.sort()\n",
    "\n",
    "    if(ListS1Mean!=[] and ListS1Mean[0][len(ListS1Mean[0])-33:len(ListS1Mean[0])-23]!=\"0000000000\"):\n",
    "        raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "    if(ListS1StdD!=[] and ListS1StdD[0][len(ListS1StdD[0])-33:len(ListS1StdD[0])-23]!=\"0000000000\"):\n",
    "        raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "    if(ListS2Mean!=[] and ListS2Mean[0][len(ListS2Mean[0])-33:len(ListS2Mean[0])-23]!=\"0000000000\"):\n",
    "        raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "    if(ListS2StdD!=[] and ListS2StdD[0][len(ListS2StdD[0])-33:len(ListS2StdD[0])-23]!=\"0000000000\"):\n",
    "        raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "\n",
    "\n",
    "    if ListS1Mean!=[] and ListS2Mean!=[] and len(ListS2Mean)!=len(ListS1Mean):\n",
    "        raise Exception (\"ERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet\")\n",
    "    if ListS1StdD!=[] and ListS2StdD!=[] and len(ListS2StdD)!=len(ListS1StdD):\n",
    "        raise Exception (\"ERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    firstItem = None\n",
    "    if(ListS1Mean!=[]):\n",
    "        firstItem=ListS1Mean[0]\n",
    "    elif (ListS2Mean!=[]):\n",
    "        firstItem=ListS2Mean[0]\n",
    "    else :\n",
    "        raise Exception (\"ERROR: no data found. Both Sentinel-1 and Sentinel-2 lists are empty\")\n",
    "\n",
    "    tmpDF = pd.read_csv(firstItem)\n",
    "    dfFieldData = pd.read_csv(fieldDataDir)\n",
    "    lenOfFieldData = len(dfFieldData.index)\n",
    "    currentMin = 0\n",
    "    currentMax = samplingSize\n",
    "    fileNames = firstItem[0:len(firstItem)-34] \n",
    "    head, fileNames = os.path.split(fileNames)\n",
    "\n",
    "    count = 0\n",
    "    while currentMin<lenOfFieldData :\n",
    "        strCurrentMin = str(currentMin  ).rjust(10,'0')\n",
    "        strCurrentMax = str(currentMax-1).rjust(10,'0')\n",
    "        FilenamesWithSampling = fileNames+\"_\"+strCurrentMin+\"_\"+strCurrentMax\n",
    "        subsetFieldDF = dfFieldData.iloc[currentMin:currentMax]\n",
    "        dfMean=subsetFieldDF\n",
    "        dfStdD=subsetFieldDF\n",
    "        \n",
    "        if(count<len(ListS1Mean)):\n",
    "            tmpDF = pd.read_csv(ListS1Mean[count])\n",
    "            tmpDF = tmpDF.reindex(sorted(tmpDF.columns),axis=1)\n",
    "            dfMean = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "        if(count<len(ListS2Mean)):\n",
    "            tmpDF = pd.read_csv(ListS2Mean[count])\n",
    "            tmpDF = tmpDF.reindex(sorted(tmpDF.columns),axis=1)\n",
    "            dfMean = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "        \n",
    "        if(count<len(ListS1StdD)):\n",
    "            tmpDF = pd.read_csv(ListS1StdD[count])\n",
    "            tmpDF = tmpDF.reindex(sorted(tmpDF.columns),axis=1)\n",
    "            dfStdD = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "        if(count<len(ListS2StdD)):\n",
    "            tmpDF = pd.read_csv(ListS2StdD[count])\n",
    "            tmpDF = tmpDF.reindex(sorted(tmpDF.columns),axis=1)\n",
    "            dfStdD = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "        \n",
    "        dfMean.to_csv(TmpDir+\"/\"+FilenamesWithSampling+\"_Mean.csv\", index=False)\n",
    "        dfStdD.to_csv(TmpDir+\"/\"+FilenamesWithSampling+\"_StdD.csv\", index=False)\n",
    "        count = count+1\n",
    "        currentMin = currentMax\n",
    "        currentMax = currentMax + samplingSize\n",
    "\n",
    "    ListMean=[]\n",
    "    ListStdD=[]\n",
    "    for file1 in glob.glob(TmpDir+\"/*.csv\"):\n",
    "        Mean=\"Mean.csv\"\n",
    "        StdD=\"StdD.csv\"\n",
    "        if(len(file1)>len(Mean)):\n",
    "            if   (file1[len(file1)-len(Mean):len(file1)]==Mean):\n",
    "                ListMean=ListMean+[file1]\n",
    "            elif (file1[len(file1)-len(Mean):len(file1)]==StdD):\n",
    "                ListStdD=ListStdD+[file1]\n",
    "    ListMean.sort()\n",
    "    ListStdD.sort()\n",
    "    outMean = open(ResDir+\"/\"+fileNames+\"_mean.csv\",\"w\")\n",
    "    outstdD = open(ResDir+\"/\"+fileNames+\"_stdD.csv\",\"w\")\n",
    "    if(outstdD.closed or outMean.closed):\n",
    "        raise Exception (\"ERROR: Failed to create merged files. Possibly \", ResDir, \" was not created!\")\n",
    "\n",
    "    count = 0\n",
    "    fileNo = 0\n",
    "    for file1 in ListMean:\n",
    "        fileNo = fileNo + 1\n",
    "        with open(file1) as file:\n",
    "            line = file.readline()\n",
    "            if fileNo == 1:\n",
    "                outMean.writelines(line) \n",
    "            count = 0\n",
    "            while(line):\n",
    "                if count == 0 :\n",
    "                    count = 1\n",
    "                    line = file.readline()   \n",
    "                    continue\n",
    "                outMean.writelines(line) \n",
    "                line = file.readline()   \n",
    "        f.close()\n",
    "\n",
    "    count = 0\n",
    "    fileNo = 0\n",
    "    for file1 in ListStdD:\n",
    "        fileNo = fileNo + 1\n",
    "        with open(file1) as file:\n",
    "            line = file.readline()\n",
    "            if fileNo == 1:\n",
    "                outstdD.writelines(line) \n",
    "            count = 0\n",
    "            while(line):\n",
    "                if count == 0 :\n",
    "                    count = 1\n",
    "                    line = file.readline()   \n",
    "                    continue\n",
    "                outstdD.writelines(line) \n",
    "                line = file.readline()   \n",
    "        f.close()\n",
    "\n",
    "    outMean.close()\n",
    "    outstdD.close()\n",
    "\n",
    "    shutil.rmtree(TmpDir)\n",
    "    print(\"Results are stored in \", ResDir)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
