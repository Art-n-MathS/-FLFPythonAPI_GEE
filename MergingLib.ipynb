{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_lines(file_path):\n",
    "    # Read lines from the original CSV file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Remove empty lines\n",
    "    non_empty_lines = [line for line in lines if line.strip() and not line.strip().replace(',', '').replace(' ', '') == '']\n",
    "\n",
    "    # Write non-empty lines back to the file\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(non_empty_lines)\n",
    "        # Truncate the file to remove extra bytes\n",
    "        file.truncate()\n",
    "\n",
    "    \n",
    "## @brief method that merges all the exported data from PlotToSat into \n",
    "#  a single .csv file\n",
    "#  @notes it assumes that all processes finished smoothly\n",
    "#  @param[in] nameOfCSVFolderDir the directory that contains all the exported\n",
    "#  .csv files. You need to download and extract this folder from Google Drive\n",
    "#  @param[in] fieldDataWithIdentifiers after each run, this is found at the \n",
    "#  same directory as PlotToSat .ipynb files. It is the field data with an extra\n",
    "#  column named \"indexField\". This column saves some identifiers used to merge\n",
    "#  the field data with the exported EO spectral temporal signatures\n",
    "#  @param[in] samplingSizeFile. This is also found in the same location as the \n",
    "#  .ipynb files of the PlotToSat. It contains a number that shows how many plot \n",
    "#  data were interpeted per each exported .csv file. Please note that .csv \n",
    "#  file may have less lines due to missing or masked out data\n",
    "def mergeAll(nameOfCSVFolderDir,fieldDataWithIdentifiers):\n",
    "    \n",
    "    fieldDataDir       =fieldDataWithIdentifiers\n",
    "\n",
    "    # make tmp directories\n",
    "    ResDir  = os.path.join(nameOfCSVFolderDir,\"MergedCsvs\")\n",
    "\n",
    "    if os.path.isdir(ResDir):\n",
    "        print (\"MergedCsvs Exist. Deleting all of its content!\")\n",
    "        shutil.rmtree(ResDir)\n",
    "    os.mkdir(ResDir)\n",
    "          \n",
    "    ListS1Mean=[]\n",
    "    ListS2Mean=[]\n",
    "    ListS1StdD=[]\n",
    "    ListS2StdD=[]\n",
    "    ListS1MeanDF=None\n",
    "    ListS2MeanDF=None\n",
    "    ListS1StdDDF=None\n",
    "    ListS2StdDDF=None\n",
    "    MeanDFAll   =None\n",
    "    StdDFAll    =None\n",
    "    ListS1MeanExist = False\n",
    "    ListS1StdDExist = False\n",
    "    ListS2MeanExist = False\n",
    "    ListS2StdDExist = False\n",
    "\n",
    "    \n",
    "\n",
    "    for file1 in glob.glob(nameOfCSVFolderDir+\"/*.csv\"):\n",
    "        S1Mean=\"S1_mean.csv\"\n",
    "        S2Mean=\"S2_mean.csv\"\n",
    "        S1StdD=\"S1_stdD.csv\"\n",
    "        S2StdD=\"S2_stdD.csv\"\n",
    "        if(len(file1)>11):\n",
    "            if   (file1[len(file1)-11:len(file1)]==S1Mean):\n",
    "                ListS1Mean=ListS1Mean+[file1]\n",
    "            elif (file1[len(file1)-11:len(file1)]==S2Mean):\n",
    "                ListS2Mean=ListS2Mean+[file1]\n",
    "            elif (file1[len(file1)-11:len(file1)]==S1StdD):\n",
    "                ListS1StdD=ListS1StdD+[file1]\n",
    "            elif (file1[len(file1)-11:len(file1)]==S2StdD):\n",
    "                ListS2StdD=ListS2StdD+[file1]\n",
    "            elif (file1[len(file1)-11:len(file1)]==\"tifiers.csv\"): #in case field data are added in the nameOfCSVFolderDir\n",
    "                print(file1 , \" is suspected to be the field data file\")\n",
    "            else :\n",
    "                print(\"WARNING: \", file1, \" is ignored since it is not recognised as an output of the system\")\n",
    "\n",
    "\n",
    "\n",
    "    print (\"ListS1Mean\",len(ListS1Mean),\"    ListS2Mean \", len(ListS2Mean), \"     ListS1StdD \", len(ListS1StdD), \"     ListS2StdD \", len(ListS2StdD))\n",
    "    if (len(ListS1Mean)>0):\n",
    "        ListS1MeanExist = True \n",
    "    if (len(ListS1StdD)>0):\n",
    "        ListS1StdDExist = True\n",
    "    if (len(ListS2Mean)>0):\n",
    "        ListS2MeanExist = True\n",
    "    if (len(ListS2StdD)>0):\n",
    "        ListS2StdDExist = True\n",
    "        \n",
    "    # if S1 Mean exist merge into a single dataframe\n",
    "    if(ListS1MeanExist):    \n",
    "        ListS1Mean.sort()\n",
    "        i=0\n",
    "        while(i<len(ListS1Mean)):\n",
    "            #print(ListS1Mean[i],\"***\")\n",
    "            try:\n",
    "                tmpDF = pd.read_csv(ListS1Mean[i],dtype=str, keep_default_na=False)\n",
    "                tmpDF[\"indexField\"] = tmpDF[\"indexField\"].astype(int)  \n",
    "                tmpDF = tmpDF.drop(columns=[\".geo\",\"system:index\"])\n",
    "                ListS1MeanDF = pd.concat([ListS1MeanDF,tmpDF],ignore_index=True,axis=0)\n",
    "            except ValueError:\n",
    "                print(\"WARNING: File \", ListS1Mean[i], \" failed to be added to the merged file!\")    \n",
    "            i=i+1\n",
    "    if(ListS1StdDExist):    \n",
    "        ListS1StdD.sort()\n",
    "        i=0\n",
    "        while(i<len(ListS1StdD)):\n",
    "            try:\n",
    "                tmpDF = pd.read_csv(ListS1StdD[i],dtype=str, keep_default_na=False)\n",
    "                tmpDF[\"indexField\"] = tmpDF[\"indexField\"].astype(int)  \n",
    "                tmpDF = tmpDF.drop(columns=[\".geo\",\"system:index\"])\n",
    "                ListS1StdDDF = pd.concat([ListS1StdDDF,tmpDF],ignore_index=True,axis=0)\n",
    "            except ValueError:\n",
    "                print (\"WARNING: File \", ListS1StdD[i], \" failed to be added to the merged file!\")\n",
    "            i=i+1\n",
    "        \n",
    "    if(ListS2MeanExist):    \n",
    "        ListS2Mean.sort()\n",
    "        i=0\n",
    "        while(i<len(ListS2Mean)):\n",
    "            try:\n",
    "                tmpDF = pd.read_csv(ListS2Mean[i],dtype=str, keep_default_na=False)\n",
    "                tmpDF[\"indexField\"] = tmpDF[\"indexField\"].astype(int)  \n",
    "                tmpDF = tmpDF.drop(columns=[\".geo\",\"system:index\"])\n",
    "                ListS2MeanDF = pd.concat([ListS2MeanDF,tmpDF],ignore_index=True,axis=0)\n",
    "            except ValueError:\n",
    "                print (\"WARNING: File \", ListS2Mean[i], \" failed to be added to the merged file!\")\n",
    "\n",
    "            i=i+1\n",
    "        \n",
    "    if(ListS2StdDExist):    \n",
    "        ListS2StdD.sort()\n",
    "        i=0\n",
    "        while(i<len(ListS2StdD)):\n",
    "            try:\n",
    "                tmpDF = pd.read_csv(ListS2StdD[i],dtype=str, keep_default_na=False)\n",
    "                tmpDF[\"indexField\"] = tmpDF[\"indexField\"].astype(int)  \n",
    "                tmpDF = tmpDF.drop(columns=[\".geo\",\"system:index\"])\n",
    "                ListS2StdDDF = pd.concat([ListS2StdDDF,tmpDF],ignore_index=True,axis=0)\n",
    "            except ValueError:\n",
    "                    print (\"WARNING: File \", ListS2StdD[i], \" failed to be added to the merged file!\")\n",
    "            i=i+1\n",
    "        \n",
    "            \n",
    "      \n",
    "    firstItem = None\n",
    "    if(ListS1Mean!=[]):\n",
    "        firstItem=ListS1Mean[0]\n",
    "    elif (ListS2Mean!=[]):\n",
    "        firstItem=ListS2Mean[0]\n",
    "    else :\n",
    "        raise Exception (\"ERROR: no data found. Both Sentinel-1 and Sentinel-2 lists are empty\")\n",
    "    fileNames = firstItem[0:len(firstItem)-34] \n",
    "    head, fileNames = os.path.split(fileNames)\n",
    "    \n",
    "    \n",
    "    dfFieldData = pd.read_csv(fieldDataDir,dtype=str, keep_default_na=False)\n",
    "    dfFieldData[\"indexField\"] = dfFieldData[\"indexField\"].astype(int)    \n",
    "    \n",
    "    MeanDFAll = dfFieldData\n",
    "    StdDFAll  = dfFieldData \n",
    "    \n",
    "    # if S1 Mean exist merge into a single dataframe\n",
    "    if(ListS1MeanExist):    \n",
    "        MeanDFAll =pd.merge(MeanDFAll,ListS1MeanDF,how='left',on=['indexField'])\n",
    "\n",
    "    if(ListS1StdDExist):    \n",
    "        StdDFAll = pd.merge(StdDFAll,ListS1StdDDF,how='left',on=['indexField'])\n",
    "\n",
    "    if(ListS2MeanExist):    \n",
    "        MeanDFAll = pd.merge(MeanDFAll,ListS2MeanDF,how='left',on=['indexField'])\n",
    "        \n",
    "    if(ListS2StdDExist):    \n",
    "        StdDFAll = pd.merge(StdDFAll,ListS2StdDDF,how='left',on=['indexField'])\n",
    "\n",
    "\n",
    "    MeanDFAll.iloc[:, -1] = MeanDFAll.iloc[:, -1].str.strip()\n",
    "    StdDFAll.iloc [:, -1] = StdDFAll.iloc [:, -1].str.strip()\n",
    "   \n",
    "    outMean = open(ResDir+\"/\"+fileNames+\"_mean.csv\",\"w\")\n",
    "    outstdD = open(ResDir+\"/\"+fileNames+\"_stdD.csv\",\"w\")\n",
    "    MeanDFAll.to_csv(outMean,encoding='utf-8',index=False)\n",
    "    StdDFAll.to_csv (outstdD,encoding='utf-8',index=False)\n",
    "\n",
    "    remove_empty_lines(ResDir+\"/\"+fileNames+\"_mean.csv\")\n",
    "    remove_empty_lines(ResDir+\"/\"+fileNames+\"_stdD.csv\")\n",
    "\n",
    "    remove_empty_lines(ResDir+\"/\"+fileNames+\"_mean.csv\")\n",
    "    remove_empty_lines(ResDir+\"/\"+fileNames+\"_stdD.csv\")\n",
    "   \n",
    "\n",
    "    \n",
    "    print(\"Results are stored in \", ResDir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
