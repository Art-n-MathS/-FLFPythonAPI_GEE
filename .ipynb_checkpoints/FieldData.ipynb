{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinate system of Spain field data: EPSG: 3042\n",
    "\n",
    "# info from: https://gis.stackexchange.com/questions/362582/coordinate-system-mismatch-in-folium \n",
    "# all coordinates passed to Leaflet functions/methods are always EPSG:4326.\n",
    "# [latitude, longitude]\n",
    "\n",
    "# when defining/creating map with folium.Map call, actual crs of map has to be specified. Map is in EPSG:3857\n",
    "\n",
    "# transforming coordinates with gdal:\n",
    "# https://gdal.org/programs/gdaltransform.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# check if GEE is already imported to avoid requesting authenticatiation multiple times\n",
    "modulename = 'ee'\n",
    "if modulename not in sys.modules: \n",
    "   # import GEE and Authenticate, token or log in will be asked from web browser\n",
    "   import ee\n",
    "   #ee.Authenticate()\n",
    "   ee.Initialize()\n",
    "else:\n",
    "   print('GEE already imported')\n",
    "   # google earth engine already imported and authenticated\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "var table = ee.FeatureCollection([\n",
    "  ee.Geometry.Point([10, 0]),\n",
    "  ee.Geometry.Point([10, 0.1]),\n",
    "  ee.Geometry.Point([10, 0.2])\n",
    "])\n",
    "\n",
    "var buffered = table.map(function (feature) {\n",
    "  return feature.buffer(5000, 1)\n",
    "})\n",
    "\"\"\"\n",
    "\n",
    "class FieldData: \n",
    "    # constructor\n",
    "    def __init__(self,csvFileName, proj):\n",
    "        self.proj = proj \n",
    "        low_memory=False\n",
    "        self.df = pd.read_csv(csvFileName) \n",
    "        self.df = self.df.reset_index()\n",
    "        self.indexLb = \"indexField\"\n",
    "        self.df[self.indexLb] = list(range(1,len(self.df)+1))\n",
    "        self.bufferredPoints = None\n",
    "        self.sampleSize = 300\n",
    "        self.exportPlotDataWithAddedIdentifiers(\"FieldDataWithIdentifiers.csv\")\n",
    "\n",
    "\n",
    "    # method that returns the number of rows/plot data contained within the csv file\n",
    "    def getLen(self):\n",
    "        return len(self.df.index)\n",
    "   \n",
    "    \"\"\"\n",
    "    # 2nd constructor that can reset the class using a given dataframe\n",
    "    def reset(self, dataframe, proj):\n",
    "        self.proj = proj \n",
    "        low_memory=False\n",
    "        self.df = dataframe\n",
    "        self.distance = 100\n",
    "        if self.indexLb in self.df.columns:\n",
    "           self.df.drop(columns=[self.indexLb])\n",
    "        self.df[self.indexLb] = list(range(1,len(self.df)+1))\n",
    "        self.bufferredPoints = None\n",
    "        self.sampleSize = 300\n",
    "        self.exportPlotDataWithAddedIdentifiers(\"FieldDataWithIdentifiers.csv\")\n",
    "    \"\"\"\n",
    "\n",
    "    ## method that returns the smallest and bigger available year withing the field data\n",
    "    ## @param[in] yearCol the name of the column that states the years\n",
    "    ## @returns [min,max] the smallest and bigger year included\n",
    "    def getMinMaxYear(self,yearlabel):\n",
    "        years = self.df[yearlabel]\n",
    "        return([min(years),max(years)])\n",
    "    \n",
    "    # @brief method that keeps the years of interests (inclusive) and discards the rest\n",
    "    def filterYearsOfInterest(self,startYear,endYear,yearlabel):\n",
    "        self.df = self.df[self.df[yearlabel].isin(list(range(startYear,endYear+1)))]\n",
    "        self.df = self.df.reset_index()\n",
    "        return None\n",
    "    \n",
    "    def bufferPoint(self,feature):\n",
    "        return feature.buffer(self.distance, 1)\n",
    "    \n",
    "    ## method that returns a dataframe containing the data of the year of interst\n",
    "    #  @param[in] year the year of interest\n",
    "    #  @param[in] yearlabel the name of the column containng the years\n",
    "    def getYearOfInterest(self,year,yearlabel):        \n",
    "        tmpdf = self.df[self.df[yearlabel] == year]\n",
    "        tmpdf = tmpdf.reset_index()\n",
    "        return tmpdf\n",
    "\n",
    "    # @brief method that reads the coordinates stored in the xlabel, and ylabel and creates a polygon with radius r \n",
    "    # @param[in] xlabel the label of the column containing the x coordinates\n",
    "    # @param[in] ylabel the label of the column containing the y coordinates\n",
    "    # @param[in] r size of the radius in meters\n",
    "    # @param[in] id the label of the column that defines the name of the plot\n",
    "    # @param[in] currentMin used to load a sample of the data this is the min value of the field range to be loaded\n",
    "    # @param[in] currentMax used to load a sample of the data this is the max value of the field date range to be loaded\n",
    "    def createBufferedPoints(self,xlabel, ylabel, r, currentMin,currentMax):\n",
    "        if (len(self.df)==0):\n",
    "            # then dataframe has no rows\n",
    "            return None \n",
    "        tmpdf = self.df.iloc[currentMin:currentMax]\n",
    "\n",
    "        if tmpdf.empty:\n",
    "            return None\n",
    "        \n",
    "        # create a feature collection with the first location\n",
    "        x = 0\n",
    "        y = 0 \n",
    "        indx = 0\n",
    "        for index, row in tmpdf.iterrows():\n",
    "            x    = row[xlabel]\n",
    "            y    = row[ylabel]\n",
    "            indx = row[self.indexLb]\n",
    "            break\n",
    "\n",
    "        self.bufferredPoints = None\n",
    "        # pointList is not defined in a loop to make sure memory allocation is preserved after \n",
    "        # the loop is deleted\n",
    "        self.bufferredPoints = ee.FeatureCollection(\n",
    "              [ee.Feature(\n",
    "                 ee.Geometry.Point(\n",
    "                        [x,y],self.proj\n",
    "                        ),\n",
    "                    {\n",
    "                        self.indexLb : indx,\n",
    "                        \"system:index\" : \"0\"\n",
    "                    }\n",
    "                    ).buffer(r)]\n",
    "                )\n",
    "        \n",
    "        # add other locations to the feature collection\n",
    "        i = 0\n",
    "        for index, row in tmpdf.iterrows():\n",
    "            if i==0 :\n",
    "                i = 1\n",
    "                continue\n",
    "            self.bufferredPoints = self.bufferredPoints.merge(ee.FeatureCollection(\n",
    "                [ee.Feature(\n",
    "                    ee.Geometry.Point(\n",
    "                        [row[xlabel],row[ylabel]],self.proj\n",
    "                        ),\n",
    "                    {\n",
    "                        self.indexLb : row[self.indexLb],\n",
    "                        \"system:index\" : \"0\"\n",
    "                    }\n",
    "                    ).buffer(r)]\n",
    "                ))\n",
    "        \n",
    "        return self.bufferredPoints\n",
    "\n",
    "    \n",
    "    def exportfeatureVectorsToDrive(self,collection, outCsvFeatureVectors, driveFolder, iscale):\n",
    "        if (self.pointsList == None) : \n",
    "            print (\"Plot data have not been read yet. Please call \\\"createBufferedPoints\", \\\n",
    "            \"(xlabel, ylabel, r)\\\" first\")\n",
    "            return\n",
    "        collection = collection.toBands()\n",
    "        #firstImg  =  collection.first()\n",
    "        bandNames = collection.bandNames()\n",
    "        print (bandNames.getInfo())\n",
    "        training = collection.sampleRegions(\n",
    "            collection = self.pointsList,\n",
    "            properties = [self.indexLb],\n",
    "            scale      = iscale,\n",
    "            projection = self.proj,\n",
    "            geometries = True\n",
    "        )\n",
    "        \n",
    "        # TO DO: COMMENT WHEN NOT TESTING OUTPUT AS BATCH COMMANDS ARE LIMITED\n",
    "        print(\"STARTING BATCH SCRIPT FOR EXPORTING FILE\")\n",
    "        task = ee.batch.Export.table.toDrive(**{\n",
    "            'collection' : training,\n",
    "            'description' : outCsvFeatureVectors,\n",
    "            'folder' : driveFolder,\n",
    "            'fileFormat' : \"CSV\"\n",
    "        })\n",
    "        #task.start()\n",
    "        print(\"END OF CALLING BATCH SCRIPT\")   \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    def exportPlotDataWithAddedIdentifiers(self, nameOfNewPlotFile):\n",
    "        #print(\"exporting field data to \", nameOfNewPlotFile)\n",
    "        self.df.to_csv(nameOfNewPlotFile)\n",
    "\n",
    "    def printFieldData(self):\n",
    "        print(self.df.to_string())  \n",
    "\n",
    "\n",
    "\n",
    "    # get mean and std for one band of an image for each buffered point\n",
    "    def getInfoRegions(self,collection,bandName, bpoints):\n",
    "    # bnamestr = bandName.get('band')\n",
    "        return collection.select([bandName]).reduceRegions(**{\n",
    "            'collection': bpoints.select(\"indexField\"),\n",
    "            'reducer': ee.Reducer.mean().combine(**{\n",
    "                'reducer2': ee.Reducer.stdDev(),\n",
    "                'sharedInputs': True\n",
    "            }),\n",
    "            'scale': 50#,\n",
    "            #'bestEffort': True  # Use maxPixels if you care about scale.\n",
    "        }).map(lambda feature: feature.set('bandName',bandName))  \\\n",
    "        .filter(ee.Filter.neq('mean',None))\n",
    "\n",
    "\n",
    "    def getFeatureCollection(self,collection,bpoints):\n",
    "        bandNamesImg = collection.bandNames().getInfo()\n",
    "        print('Band names: ', bandNamesImg)\n",
    "        for band in bandNamesImg :\n",
    "            if(not isinstance(band,str)):\n",
    "                bandNamesImg.remove(band)\n",
    "        featureCollection = ee.FeatureCollection([])\n",
    "        for band in bandNamesImg:\n",
    "            features = self.getInfoRegions(collection,band,bpoints)\n",
    "            featureCollection = featureCollection.merge(features)\n",
    "        return featureCollection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def processMatchesMean(self,row):\n",
    "        # Get the list of all features with a unique row ID.\n",
    "        matches = ee.List(row.get('matches'))\n",
    "        # Map a function over the list of rows to return a list of column ID and value.\n",
    "        values = matches.map(lambda feature: [ee.Feature(feature).get('bandName'), ee.Feature(feature).get('mean')])\n",
    "        # Return the row with its ID property and properties for all matching column IDs storing the output of the reducer.\n",
    "        return row.select(['indexField']).set(ee.Dictionary(values.flatten()))\n",
    "\n",
    "\n",
    "    ## Format a table of triplets into a 2D table of rowId x colId.\n",
    "    def formatMean (self,table):\n",
    "        # Get a FeatureCollection with unique row IDs.\n",
    "        rows = table.distinct('indexField')\n",
    "        filterEq = ee.Filter.equals(leftField='indexField', rightField='indexField')\n",
    "        innerJoin = ee.Join.saveAll('matches')\n",
    "        toyJoin = innerJoin.apply(primary=rows, secondary=table, condition=filterEq)\n",
    "        return toyJoin.map(algorithm = self.processMatchesMean)\n",
    "\n",
    "    def processMatchesStd(self,row):\n",
    "        # Get the list of all features with a unique row ID.\n",
    "        matches = ee.List(row.get('matches'))\n",
    "        # Map a function over the list of rows to return a list of column ID and value.\n",
    "        values = matches.map(lambda feature: [ee.Feature(feature).get('bandName'), ee.Feature(feature).get('stdD')])\n",
    "        # Return the row with its ID property and properties for all matching column IDs storing the output of the reducer.\n",
    "        return row.select(['indexField']).set(ee.Dictionary(values.flatten()))\n",
    "\n",
    "\n",
    "    ## Format a table of triplets into a 2D table of rowId x colId.\n",
    "    def formatStd (self,table):\n",
    "        # Get a FeatureCollection with unique row IDs.\n",
    "        rows = table.distinct('indexField')\n",
    "        filterEq = ee.Filter.equals(leftField='indexField', rightField='indexField')\n",
    "        innerJoin = ee.Join.saveAll('matches')\n",
    "        toyJoin = innerJoin.apply(primary=rows, secondary=table, condition=filterEq)\n",
    "        return toyJoin.map(algorithm = self.processMatchesStd)\n",
    "\n",
    "\n",
    "    # collection = s2bands\n",
    "    def exportFeaturesMeanStdCSV(self,collection,ouutCsvFeatureVectors,driveFolder):\n",
    "        if (self.bufferredPoints == None):\n",
    "            raise Exception(\"Please call createBufferedPoints(xlabel, ylabel, r) function first\" )\n",
    "        featureCollection = self.getFeatureCollection(collection,self.bufferredPoints)\n",
    "\n",
    "        tableMean = self.formatMean(featureCollection)\n",
    "        tableStd  = self.formatStd (featureCollection)\n",
    "        \n",
    "        meanName = ouutCsvFeatureVectors+\"_mean\"\n",
    "        stdName = ouutCsvFeatureVectors+\"_stdD\"\n",
    "        print (\"START EXPORTING FEATURES VECTORS OF A SINGLE FILE\")\n",
    "        task = ee.batch.Export.table.toDrive(**{\n",
    "            'collection':tableMean,\n",
    "            'description':meanName,\n",
    "            'folder': driveFolder,\n",
    "            'fileFormat':'CSV'\n",
    "        })\n",
    "        task.start()\n",
    "\n",
    "        task = ee.batch.Export.table.toDrive(**{\n",
    "            'collection':tableStd,\n",
    "            'description':stdName,\n",
    "            'folder': driveFolder,\n",
    "            'fileFormat':'CSV'\n",
    "        })\n",
    "        task.start()\n",
    "        print(\"STOP EXPORTING: CHECK PROGRESS ON GOOGLE EARTH ENGINE - FILES ON DRIVE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Class fieldData imported\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cab1d7ef7b90e69a2393a883ac82077044fd5f1d4df4dae9ffefa7c49ee44033"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
