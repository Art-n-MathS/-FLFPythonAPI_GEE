{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from scipy.stats import norm \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function 1 takes as input a csv file and calculates the mean spectral-temporal signature \n",
    "# for each available label in the given column. \n",
    "# @param[in] inCsvfile : a csv file exported from PlotToSat or a merged csv file\n",
    "# @param[in] col       : name of columns that medians will be calculated\n",
    "# @param[in] outCsvfile: name of file to be exported\n",
    "def getMeanSpectralTemporalSignatures(inCsvfile,col,outCsvfile):\n",
    "    csvDF = pd.read_csv(inCsvfile,low_memory=False) \n",
    "    labels = list(csvDF.columns)\n",
    "    if (col not in labels):\n",
    "        raise Exception(\"ERROR: \", col, \" not included in \", inCsvfile)\n",
    "    newLabels = [col] \n",
    "    l = 0\n",
    "    while (l<len(labels)):\n",
    "        if ((labels[l][0].isdigit() and labels[l][1]==\"_\") or \n",
    "            (labels[l][0].isdigit() and labels[l][1].isdigit() and labels[l][2]==\"_\")):\n",
    "            newLabels.append(labels[l])\n",
    "        l=l+1\n",
    "    newLabelsS1 = [col, '0_VHAsc','1_VHAsc','2_VHAsc','3_VHAsc', '4_VHAsc', '5_VHAsc','6_VHAsc', '7_VHAsc', '8_VHAsc', '9_VHAsc', '10_VHAsc','11_VHAsc', '0_VHDes','1_VHDes','2_VHDes','3_VHDes', '4_VHDes', '5_VHDes','6_VHDes', '7_VHDes', '8_VHDes', '9_VHDes', '10_VHDes','11_VHDes', '0_VVAsc','1_VVAsc','2_VVAsc','3_VVAsc', '4_VVAsc', '5_VVAsc','6_VVAsc', '7_VVAsc', '8_VVAsc', '9_VVAsc', '10_VVAsc','11_VVAsc', '0_VVDes','1_VVDes','2_VVDes','3_VVDes', '4_VVDes', '5_VVDes','6_VVDes', '7_VVDes', '8_VVDes', '9_VVDes', '10_VVDes','11_VVDes']\n",
    "    newLabelsS2 = [col, '0_B1',  '0_B2', '0_B3', '0_B4', '0_B5', '0_B6', '0_B7', '0_B8', '0_B8A', '0_B9', '0_B11', '0_B12', '1_B1',  '1_B2', '1_B3', '1_B4', '1_B5', '1_B6', '1_B7', '1_B8', '1_B8A', '1_B9','1_B11', '1_B12', '2_B1',  '2_B2', '2_B3', '2_B4', '2_B5', '2_B6', '2_B7', '2_B8', '2_B8A', '2_B9', '2_B11', '2_B12', '3_B1', '3_B2', '3_B3', '3_B4', '3_B5', '3_B6', '3_B7', '3_B8', '3_B8A', '3_B9', '3_B11', '3_B12',  '4_B1', '4_B2', '4_B3', '4_B4', '4_B5', '4_B6', '4_B7', '4_B8', '4_B8A', '4_B9',  '4_B11', '4_B12', '5_B1',  '5_B2', '5_B3', '5_B4', '5_B5', '5_B6', '5_B7', '5_B8', '5_B8A', '5_B9', '5_B11', '5_B12', '6_B1', '6_B2', '6_B3', '6_B4', '6_B5', '6_B6', '6_B7', '6_B8', '6_B8A', '6_B9', '6_B11', '6_B12',  '7_B1',  '7_B2', '7_B3', '7_B4', '7_B5', '7_B6', '7_B7', '7_B8', '7_B8A', '7_B9', '7_B11', '7_B12', '8_B1','8_B2', '8_B3', '8_B4', '8_B5', '8_B6', '8_B7', '8_B8', '8_B8A', '8_B9',  '8_B11', '8_B12',  '9_B1', '9_B2', '9_B3', '9_B4', '9_B5', '9_B6', '9_B7', '9_B8', '9_B8A', '9_B9', '9_B11', '9_B12',  '10_B1', '10_B2', '10_B3', '10_B4', '10_B5', '10_B6', '10_B7', '10_B8', '10_B8A', '10_B9','10_B11', '10_B12',  '11_B1',  '11_B2', '11_B3', '11_B4', '11_B5', '11_B6', '11_B7', '11_B8', '11_B8A', '11_B9', '11_B11', '11_B12']\n",
    "    print(newLabelsS1)\n",
    "    print(newLabelsS2)\n",
    "    \n",
    "    csvDFS1 = csvDF.loc[:,newLabelsS1]\n",
    "    csvDFS1=csvDFS1.groupby(col).mean()\n",
    "    csvDFS1.to_csv(outCsvfile+\"S1.csv\")\n",
    "    \n",
    "    csvDFS2 = csvDF.loc[:,newLabelsS2]\n",
    "    csvDFS2=csvDFS2.groupby(col).mean()\n",
    "    csvDFS2.to_csv(outCsvfile+\"S2.csv\")\n",
    "    \n",
    "    print(\"File exported in \", outCsvfile+\"S1.csv and \", outCsvfile+\"S2.csv\")  \n",
    "    \n",
    "# function 2 takes as input the output of function 2 and creates spectral-temporal signatures graphs for S2 and temporal signatures for S1   \n",
    "def createSpectralTemporalGraphs(inCsvFile,outFilestart):\n",
    "    inCsvFileS1 = inCsvFile+\"S1.csv\"\n",
    "        \n",
    "    csvDFS1 = pd.read_csv(inCsvFileS1)\n",
    "    labels = list(csvDFS1.columns)\n",
    "    for index, row in csvDFS1.iterrows():\n",
    "        row1 = row\n",
    "        tmplist = np.array(row1)\n",
    "        rowlist = []\n",
    "        for item in tmplist:\n",
    "            rowlist = rowlist + [item]\n",
    "        modulo = (len(rowlist)-1)%12\n",
    "        if (modulo!=0 and len(rowlist<=0)):\n",
    "            raise Exception(\"this is not a 12 months spectral temporal signature\")      \n",
    "        outImg = outFilestart+\"_\"+rowlist[0]+\"_S1.jpg\"\n",
    "        data =  [rowlist[1:13],rowlist[13:25],rowlist[25:37],rowlist[37:49]]\n",
    "        data = np.array(data)\n",
    "        months = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "        plt.plot(months,data[0],label = \"VVAsc\")\n",
    "        plt.plot(months,data[1],label = \"VVDes\")\n",
    "        plt.plot(months,data[2],label = \"VHAsc\")\n",
    "        plt.plot(months,data[3],label = \"VHDes\")\n",
    "        plt.savefig(outImg)\n",
    "        plt.clf()\n",
    "        \n",
    "        \n",
    "    inCSVFileS2 = inCsvFile+\"S2.csv\"   \n",
    "    csvDFS2 = pd.read_csv(inCSVFileS2)\n",
    " \n",
    "    labels = list(csvDFS2.columns)\n",
    "    for index, row in csvDFS2.iterrows():\n",
    "        row1 = row\n",
    "        tmplist = np.array(row1)\n",
    "        rowlist = []\n",
    "        for item in tmplist:\n",
    "            rowlist = rowlist + [item]\n",
    "        modulo = (len(rowlist)-1)%12\n",
    "        if (modulo!=0 and len(rowlist<=0)):\n",
    "            raise Exception(\"this is not a 12 months spectral temporal signature\")\n",
    "        outImg = outFilestart+\"_\"+rowlist[0]+\"_S2.jpg\"\n",
    "        print(outImg)\n",
    "        data =  [rowlist[      1:12   +1], #'0_B1',  '0_B2', '0_B3', '0_B4', '0_B5', '0_B6', '0_B7', '0_B8', '0_B8A', '0_B9', '0_B11', '0_B12', \n",
    "                 rowlist[12   +1:12* 2+1], #'1_B1',  '1_B2', '1_B3', '1_B4', '1_B5', '1_B6', '1_B7', '1_B8', '1_B8A', '1_B9','1_B11', '1_B12', \n",
    "                 rowlist[12* 2+1:12* 3+1], #'2_B1',  '2_B2', '2_B3', '2_B4', '2_B5', '2_B6', '2_B7', '2_B8', '2_B8A', '2_B9', '2_B11', '2_B12', \n",
    "                 rowlist[12* 3+1:12* 4+1], #'3_B1', '3_B2', '3_B3', '3_B4', '3_B5', '3_B6', '3_B7', '3_B8', '3_B8A', '3_B9', '3_B11', '3_B12',  \n",
    "                 rowlist[12* 4+1:12* 5+1], #'4_B1', '4_B2', '4_B3', '4_B4', '4_B5', '4_B6', '4_B7', '4_B8', '4_B8A', '4_B9',  '4_B11', '4_B12', \n",
    "                 rowlist[12* 5+1:12* 6+1], #'5_B1',  '5_B2', '5_B3', '5_B4', '5_B5', '5_B6', '5_B7', '5_B8', '5_B8A', '5_B9', '5_B11', '5_B12', \n",
    "                 rowlist[12* 6+1:12* 7+1], #'6_B1', '6_B2', '6_B3', '6_B4', '6_B5', '6_B6', '6_B7', '6_B8', '6_B8A', '6_B9', '6_B11', '6_B12',  \n",
    "                 rowlist[12* 7+1:12* 8+1], #'7_B1',  '7_B2', '7_B3', '7_B4', '7_B5', '7_B6', '7_B7', '7_B8', '7_B8A', '7_B9', '7_B11', '7_B12', \n",
    "                 rowlist[12* 8+1:12* 9+1], #'8_B1','8_B2', '8_B3', '8_B4', '8_B5', '8_B6', '8_B7', '8_B8', '8_B8A', '8_B9',  '8_B11', '8_B12',  \n",
    "                 rowlist[12* 9+1:12*10+1], #'9_B1', '9_B2', '9_B3', '9_B4', '9_B5', '9_B6', '9_B7', '9_B8', '9_B8A', '9_B9', '9_B11', '9_B12', \n",
    "                 rowlist[12*10+1:12*11+1], # '10_B1', '10_B2', '10_B3', '10_B4', '10_B5', '10_B6', '10_B7', '10_B8', '10_B8A', '10_B9','10_B11', \n",
    "                 rowlist[12*11+1:12*12+1]] #'10_B12',  '11_B1',  '11_B2', '11_B3', '11_B4', '11_B5', '11_B6', '11_B7', '11_B8', '11_B8A', '11_B9', '11_B11', '11_B12'\n",
    "        data = np.array(data)\n",
    "        data = np.transpose(data)     \n",
    "        fig, (ax, bx) = plt.subplots(nrows=1, ncols=2, num=0, figsize=(16, 8),\n",
    "                             subplot_kw={'projection': '3d'})\n",
    "        for i in range(data.shape[1]):\n",
    "            ax.plot3D(np.repeat(i, data.shape[0]), np.arange(data.shape[0]),data[:, i])\n",
    "        gridX, gridY = np.mgrid[1:data.shape[0]:data.shape[0] * 1j,\n",
    "                                1:data.shape[1]:data.shape[1] * 1j]\n",
    "        ax.set_xlabel('Band')\n",
    "        ax.set_ylabel('Month')\n",
    "        ax.set_zlabel('Mean Spectral Value')\n",
    "        bx.set_xlabel('Band')\n",
    "        bx.set_ylabel('Month')\n",
    "        bx.set_xticklabels([\"B1\",\"B3\",\"B5\",\"B7\",\"B8A\",\"B11\", \"\"])\n",
    "        ax.set_xticklabels([\"B1\",\"B1\",\"B3\",\"B5\",\"B7\",\"B8A\",\"B11\", \"\"])\n",
    "        bx.set_yticklabels([\"Jan\",  \"Mar\",  \"May\",\"Jul\",  \"Sep\",  \"Nov\"])\n",
    "        ax.set_yticklabels([\"Jan\",\"Jan\", \"Mar\", \"May\", \"Jul\", \"Sep\", \"Nov\"])\n",
    "        pSurf = bx.plot_surface(gridY, gridX, data, cmap='viridis')\n",
    "        fig.colorbar(pSurf)\n",
    "        plt.savefig(outImg)\n",
    "        plt.clf()\n",
    "    print(\"hello\")\n",
    "    \n",
    "    \n",
    "# function 3 takes as input the outpus of function 1 and produces the annual mean for each band \n",
    "def getMeanPerBandfromMeans(inCsvFile,col,outCsvfile):\n",
    "    inCsvFileS1 = inCsvFile+\"S1.csv\"\n",
    "    inCsvFileS2 = inCsvFile+\"S2.csv\"\n",
    "\n",
    "    csvDFS2 = pd.read_csv(inCsvFileS2)\n",
    "    # '0_B1',  '0_B2', '0_B3', '0_B4', '0_B5', '0_B6', '0_B7', '0_B8', '0_B8A', '0_B9', '0_B11', '0_B12', \n",
    "    dfS2  = csvDFS2[[col]]\n",
    "    dfS2 ['B1' ] = csvDFS2 [['0_B1', '1_B1', '2_B1', '3_B1', '4_B1', '5_B1', '6_B1', '7_B1', '8_B1', '9_B1', '10_B1', '11_B1' ]].mean(axis=1) # '0_B1', \n",
    "    dfS2 ['B2' ] = csvDFS2 [['0_B2', '1_B2', '2_B2', '3_B2', '4_B2', '5_B2', '6_B2', '7_B2', '8_B2', '9_B2', '10_B2', '11_B2' ]].mean(axis=1) # '0_B2', \n",
    "    dfS2 ['B3' ] = csvDFS2 [['0_B3', '1_B3', '2_B3', '3_B3', '4_B3', '5_B3', '6_B3', '7_B3', '8_B3', '9_B3', '10_B3', '11_B3' ]].mean(axis=1) # '0_B3\n",
    "    dfS2 ['B4' ] = csvDFS2 [['0_B4', '1_B4', '2_B4', '3_B4', '4_B4', '5_B4', '6_B4', '7_B4', '8_B4', '9_B4', '10_B4', '11_B4' ]].mean(axis=1) # '0_B4', \n",
    "    dfS2 ['B5' ] = csvDFS2 [['0_B5', '1_B5', '2_B5', '3_B5', '4_B5', '5_B5', '6_B5', '7_B5', '8_B5', '9_B5', '10_B5', '11_B5' ]].mean(axis=1) # '0_B5',\n",
    "    dfS2 ['B6' ] = csvDFS2 [['0_B6', '1_B6', '2_B6', '3_B6', '4_B6', '5_B6', '6_B6', '7_B6', '8_B6', '9_B6', '10_B6', '11_B6' ]].mean(axis=1) # '0_B6',\n",
    "    dfS2 ['B7' ] = csvDFS2 [['0_B7', '1_B7', '2_B7', '3_B7', '4_B7', '5_B7', '6_B7', '7_B7', '8_B7', '9_B7', '10_B7', '11_B7' ]].mean(axis=1) # '0_B7',\n",
    "    dfS2 ['B8' ] = csvDFS2 [['0_B8', '1_B8', '2_B8', '3_B8', '4_B8', '5_B8', '6_B8', '7_B8', '8_B8', '9_B8', '10_B8', '11_B8' ]].mean(axis=1) # '0_B8',\n",
    "    dfS2 ['B8A'] = csvDFS2 [['0_B8A','1_B8A','2_B8A','3_B8A','4_B8A','5_B8A','6_B8A','7_B8A','8_B8A','9_B8A','10_B8A','11_B8A']].mean(axis=1) # '0_B8A',\n",
    "    dfS2 ['B9' ] = csvDFS2 [['0_B9', '1_B9', '2_B9', '3_B9', '4_B9', '5_B9', '6_B9', '7_B9', '8_B9', '9_B9', '10_B9', '11_B9' ]].mean(axis=1) # '0_B9',\n",
    "    dfS2 ['B11'] = csvDFS2 [['0_B11','1_B11','2_B11','3_B11','4_B11','5_B11','6_B11','7_B11','8_B11','9_B11','10_B11','11_B11']].mean(axis=1) # '0_B11',\n",
    "    dfS2 ['B12'] = csvDFS2 [['0_B12','1_B12','2_B12','3_B12','4_B12','5_B12','6_B12','7_B12','8_B12','9_B12','10_B12','11_B12']].mean(axis=1) # '0_B12',\n",
    "    dfS2.to_csv(outCsvfile+\"S2.csv\")\n",
    "    print (\"Means saved in \", outCsvfile+\"S2.csv\")\n",
    "\n",
    "    csvDFS1 = pd.read_csv(inCsvFileS1)\n",
    "    # '0_VHAsc' 0_VHDes 0_VVAsc 0_VVDes\n",
    "    dfS1 =  csvDFS1[[col]]\n",
    "    dfS1['VHAsc'] = csvDFS1[['0_VHAsc', '1_VHAsc', '2_VHAsc', '3_VHAsc', '4_VHAsc', '5_VHAsc', '6_VHAsc', '7_VHAsc', '8_VHAsc', '9_VHAsc', '10_VHAsc', '11_VHAsc']].mean(axis=1) # '0_VHAsc',\n",
    "    dfS1['VVAsc'] = csvDFS1[['0_VVAsc', '1_VVAsc', '2_VVAsc', '3_VVAsc', '4_VVAsc', '5_VVAsc', '6_VVAsc', '7_VVAsc', '8_VVAsc', '9_VVAsc', '10_VVAsc', '11_VVAsc']].mean(axis=1)  # '0_VVAsc',  \n",
    "    dfS1['VHDes'] = csvDFS1[['0_VHDes', '1_VHDes', '2_VHDes', '3_VHDes', '4_VHDes', '5_VHDes', '6_VHDes', '7_VHDes', '8_VHDes', '9_VHDes', '10_VHDes', '11_VHDes']].mean(axis=1)  # '0_VHDes',      \n",
    "    dfS1['VVDes'] = csvDFS1[['0_VVDes', '1_VVDes', '2_VVDes', '3_VVDes', '4_VVDes', '5_VVDes', '6_VVDes', '7_VVDes', '8_VVDes', '9_VVDes', '10_VVDes', '11_VVDes']].mean(axis=1)  # '0_VVDes',  \n",
    "    dfS1.to_csv(outCsvfile+\"S1.csv\")\n",
    "    print (\"Means saved in \", outCsvfile+\"S1.csv\")\n",
    "\n",
    "# function 4 takes as input the outpus of PlotToSat and produces the annual mean for each band \n",
    "def getMeanPerBand(inCsvFile,col,outCsvfile):\n",
    "    csvDFS = pd.read_csv(inCsvFile)\n",
    "    # '0_B1',  '0_B2', '0_B3', '0_B4', '0_B5', '0_B6', '0_B7', '0_B8', '0_B8A', '0_B9', '0_B11', '0_B12', \n",
    "    dfS2  = csvDFS[[col]]\n",
    "    dfS2 ['B1' ] = csvDFS [['0_B1', '1_B1', '2_B1', '3_B1', '4_B1', '5_B1', '6_B1', '7_B1', '8_B1', '9_B1', '10_B1', '11_B1' ]].mean(axis=1) # '0_B1', \n",
    "    dfS2 ['B2' ] = csvDFS [['0_B2', '1_B2', '2_B2', '3_B2', '4_B2', '5_B2', '6_B2', '7_B2', '8_B2', '9_B2', '10_B2', '11_B2' ]].mean(axis=1) # '0_B2', \n",
    "    dfS2 ['B3' ] = csvDFS [['0_B3', '1_B3', '2_B3', '3_B3', '4_B3', '5_B3', '6_B3', '7_B3', '8_B3', '9_B3', '10_B3', '11_B3' ]].mean(axis=1) # '0_B3\n",
    "    dfS2 ['B4' ] = csvDFS [['0_B4', '1_B4', '2_B4', '3_B4', '4_B4', '5_B4', '6_B4', '7_B4', '8_B4', '9_B4', '10_B4', '11_B4' ]].mean(axis=1) # '0_B4', \n",
    "    dfS2 ['B5' ] = csvDFS [['0_B5', '1_B5', '2_B5', '3_B5', '4_B5', '5_B5', '6_B5', '7_B5', '8_B5', '9_B5', '10_B5', '11_B5' ]].mean(axis=1) # '0_B5',\n",
    "    dfS2 ['B6' ] = csvDFS [['0_B6', '1_B6', '2_B6', '3_B6', '4_B6', '5_B6', '6_B6', '7_B6', '8_B6', '9_B6', '10_B6', '11_B6' ]].mean(axis=1) # '0_B6',\n",
    "    dfS2 ['B7' ] = csvDFS [['0_B7', '1_B7', '2_B7', '3_B7', '4_B7', '5_B7', '6_B7', '7_B7', '8_B7', '9_B7', '10_B7', '11_B7' ]].mean(axis=1) # '0_B7',\n",
    "    dfS2 ['B8' ] = csvDFS [['0_B8', '1_B8', '2_B8', '3_B8', '4_B8', '5_B8', '6_B8', '7_B8', '8_B8', '9_B8', '10_B8', '11_B8' ]].mean(axis=1) # '0_B8',\n",
    "    dfS2 ['B8A'] = csvDFS [['0_B8A','1_B8A','2_B8A','3_B8A','4_B8A','5_B8A','6_B8A','7_B8A','8_B8A','9_B8A','10_B8A','11_B8A']].mean(axis=1) # '0_B8A',\n",
    "    dfS2 ['B9' ] = csvDFS [['0_B9', '1_B9', '2_B9', '3_B9', '4_B9', '5_B9', '6_B9', '7_B9', '8_B9', '9_B9', '10_B9', '11_B9' ]].mean(axis=1) # '0_B9',\n",
    "    dfS2 ['B11'] = csvDFS [['0_B11','1_B11','2_B11','3_B11','4_B11','5_B11','6_B11','7_B11','8_B11','9_B11','10_B11','11_B11']].mean(axis=1) # '0_B11',\n",
    "    dfS2 ['B12'] = csvDFS [['0_B12','1_B12','2_B12','3_B12','4_B12','5_B12','6_B12','7_B12','8_B12','9_B12','10_B12','11_B12']].mean(axis=1) # '0_B12',\n",
    "    dfS2.to_csv(outCsvfile+\"S2.csv\")\n",
    "    print (\"Means saved in \", outCsvfile+\"S2.csv\")\n",
    "\n",
    "    # '0_VHAsc' 0_VHDes 0_VVAsc 0_VVDes\n",
    "    dfS1 =  csvDFS[[col]]\n",
    "    dfS1['VHAsc'] = csvDFS[['0_VHAsc', '1_VHAsc', '2_VHAsc', '3_VHAsc', '4_VHAsc', '5_VHAsc', '6_VHAsc', '7_VHAsc', '8_VHAsc', '9_VHAsc', '10_VHAsc', '11_VHAsc']].mean(axis=1) # '0_VHAsc',\n",
    "    dfS1['VVAsc'] = csvDFS[['0_VVAsc', '1_VVAsc', '2_VVAsc', '3_VVAsc', '4_VVAsc', '5_VVAsc', '6_VVAsc', '7_VVAsc', '8_VVAsc', '9_VVAsc', '10_VVAsc', '11_VVAsc']].mean(axis=1)  # '0_VVAsc',  \n",
    "    dfS1['VHDes'] = csvDFS[['0_VHDes', '1_VHDes', '2_VHDes', '3_VHDes', '4_VHDes', '5_VHDes', '6_VHDes', '7_VHDes', '8_VHDes', '9_VHDes', '10_VHDes', '11_VHDes']].mean(axis=1)  # '0_VHDes',      \n",
    "    dfS1['VVDes'] = csvDFS[['0_VVDes', '1_VVDes', '2_VVDes', '3_VVDes', '4_VVDes', '5_VVDes', '6_VVDes', '7_VVDes', '8_VVDes', '9_VVDes', '10_VVDes', '11_VVDes']].mean(axis=1)  # '0_VVDes',  \n",
    "    dfS1.to_csv(outCsvfile+\"S1.csv\")\n",
    "    print (\"Means saved in \", outCsvfile+\"S1.csv\")\n",
    "    \n",
    "    \n",
    "# function 5 that adds NDVI to the S2 output of function 3 or 4 \n",
    "def addNDVI(inCsvFile, outCsvFile):\n",
    "    dfS2 = pd.read_csv(inCsvFile+\"S2.csv\")\n",
    "    dfS2['NDVI'] = (dfS2['B8']-dfS2['B4'])/(dfS2['B8']+dfS2['B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    dfS2.to_csv(outCsvFile)\n",
    "    print (outCsvFile, \"saved\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# function 6 that takes as input a csv file and exports a histogram with the distribution line\n",
    "# @param[in] col, the name of the colmun of which the histogram will be derived\n",
    "def saveHist(inCsvFile, col, outHist):\n",
    "    df = pd.read_csv(inCsvFile) \n",
    "    data = np.array(df[col].tolist())  \n",
    "    data = [i for i in data if i is not None]\n",
    "    data = [x for x in data if ~np.isnan(x)]\n",
    "    data = [i for i in data if i!='nan']\n",
    "    mu, std = norm.fit(data)  \n",
    "  \n",
    "    # Plot the histogram. \n",
    "    plt.hist(data, bins=25, density=True, alpha=0.6, color='b') \n",
    "    \n",
    "    # Plot the PDF. \n",
    "    xmin, xmax = plt.xlim() \n",
    "    x = np.linspace(xmin, xmax, 100) \n",
    "    p = norm.pdf(x, mu, std) \n",
    "    \n",
    "    plt.plot(x, p, 'k', linewidth=2) \n",
    "    title = \"Mean: {:.2f}, Std {:.2f}\".format(mu, std) \n",
    "    plt.title(title)   \n",
    "    plt.savefig(outHist)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "\n",
    "## function 7 that takes as input a csv file and exports a csv files for each available label in a given column\n",
    "# for each available label in the given column. \n",
    "# @param[in] inCsvfile : a csv file exported from PlotToSat or a merged csv file\n",
    "# @param[in] col       : name of columns that medians will be calculated\n",
    "# @param[in] outCsvfile: name of file to be exported\n",
    "def divideDataAccordingLabels(inCsvfile,col,outCsvfolder):\n",
    "    if (os.path.exists(outCsvfolder)):\n",
    "       print(\"WARNING: Directory \", outCsvfolder, \"exist.\")\n",
    "    else:\n",
    "        os.mkdir(outCsvfolder)\n",
    "    \n",
    "    csvDF = pd.read_csv(inCsvfile,low_memory=False) \n",
    "    \n",
    "    dfs = [x.reset_index(drop=True) for _, x in csvDF.groupby(col)]\n",
    "    [x.to_csv(f\"{outCsvfolder}{x[col][0]}.csv\", index=False) for x in dfs]    \n",
    "    \n",
    " \n",
    "## function 8 for each biome get th means and the hist graphs using previous graphs and spectral-temporal graphs\n",
    "def getAll(inCsvFile,col,OutFolder):\n",
    "    if (OutFolder[-1]!=[\"/\"]):\n",
    "        OutFolder = OutFolder+\"/\"\n",
    "    \n",
    "    if (os.path.exists(OutFolder)):\n",
    "       print(\"WARNING: Directory \", OutFolder, \"exist. \", OutFolder, \"is removed!\")\n",
    "       shutil.rmtree(OutFolder)\n",
    "    os.mkdir(OutFolder)\n",
    "       \n",
    "    getMeanSpectralTemporalSignatures(inCsvFile,col,OutFolder+\"classMeans.csv\")\n",
    "    createSpectralTemporalGraphs(OutFolder+\"classMeans.csv\",OutFolder+\"classMeans\") \n",
    "    \n",
    "    getMeanPerBand(inCsvFile,col,OutFolder+\"_annualMeans.csv\")\n",
    "    addNDVI(OutFolder+\"_annualMeans.csv\", OutFolder+\"_annualMeans_NDVI.csv\")\n",
    "    divideDataAccordingLabels(OutFolder+\"_annualMeans_NDVI.csv\",col,OutFolder)\n",
    "\n",
    "    csvDFmeans = pd.read_csv(OutFolder+\"classMeans.csvS1.csv\")\n",
    "    labels = np.array(csvDFmeans[col].tolist()) # the unique labels of the column of interest\n",
    "    \n",
    "    labels = [i for i in labels if i is not None]\n",
    "    labels = [i for i in labels if i!='nan']\n",
    "    print (labels)\n",
    "    \n",
    "    for label in labels :\n",
    "        saveHist(OutFolder+label+\".csv\",\"NDVI\",OutFolder+label+\"_hist.jpg\") \n",
    "         \n",
    "## function 9 takes the output of PlotToSat and adds the NDVI of each month\n",
    "def addNDVIpermonth(inCsvFile,Col,outCsvFile):\n",
    "    df = pd.read_csv(inCsvFile,low_memory=False) \n",
    "    df[ '0_NDVI'] = (df[ '0_B8']-df[ '0_B4'])/(df[ '0_B8']+df[ '0_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '1_NDVI'] = (df[ '1_B8']-df[ '1_B4'])/(df[ '1_B8']+df[ '1_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '2_NDVI'] = (df[ '2_B8']-df[ '2_B4'])/(df[ '2_B8']+df[ '2_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '3_NDVI'] = (df[ '3_B8']-df[ '3_B4'])/(df[ '3_B8']+df[ '3_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '4_NDVI'] = (df[ '4_B8']-df[ '4_B4'])/(df[ '4_B8']+df[ '4_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '5_NDVI'] = (df[ '5_B8']-df[ '5_B4'])/(df[ '5_B8']+df[ '5_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '6_NDVI'] = (df[ '6_B8']-df[ '6_B4'])/(df[ '6_B8']+df[ '6_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '7_NDVI'] = (df[ '7_B8']-df[ '7_B4'])/(df[ '7_B8']+df[ '7_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '8_NDVI'] = (df[ '8_B8']-df[ '8_B4'])/(df[ '8_B8']+df[ '8_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '9_NDVI'] = (df[ '9_B8']-df[ '9_B4'])/(df[ '9_B8']+df[ '9_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df['10_NDVI'] = (df['10_B8']-df['10_B4'])/(df['10_B8']+df['10_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df['11_NDVI'] = (df['11_B8']-df['11_B4'])/(df['11_B8']+df['11_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df = df[[Col, \"0_NDVI\", \"1_NDVI\",\"2_NDVI\",\"3_NDVI\", \"4_NDVI\", \"5_NDVI\", \"6_NDVI\", \"7_NDVI\", \"8_NDVI\", \"9_NDVI\", \"10_NDVI\", \"11_NDVI\"]]\n",
    "    df.to_csv(outCsvFile)\n",
    "    print (\"Csv file with NDVs export in \", outCsvFile)\n",
    "    \n",
    "    \n",
    "## function 10 takes as input the output of function 9, for each unique label in Col it gets the mean for each monthly NDVI \n",
    "def getMeanNDVIsPerMonthForClass(inCsvFile,Col,outCsvFile):\n",
    "    csvDF = pd.read_csv(inCsvFile,low_memory=False)\n",
    "    # '0_NDVI',  '1_NDVI', '2_NDVI', '3_NDVI', '4_NDVI', '5_NDVI', '6_NDVI', '7_NDVI', '8_NDVI',  '9_NDVI', '10_NDVI', '11_NDVI', \n",
    "    labels = list(csvDF.columns)\n",
    "    if (col not in labels):\n",
    "        raise Exception(\"ERROR: \", col, \" not included in \", inCsvfile)\n",
    "    newLabels = [col] \n",
    "    l = 0\n",
    "    while (l<len(labels)):\n",
    "        if ((labels[l][0].isdigit() and labels[l][1]==\"_\") or \n",
    "            (labels[l][0].isdigit() and labels[l][1].isdigit() and labels[l][2]==\"_\")):\n",
    "            newLabels.append(labels[l])\n",
    "        l=l+1\n",
    "    \n",
    "    newLabelsS2 = [Col, '0_NDVI',  '1_NDVI', '2_NDVI', '3_NDVI', '4_NDVI', '5_NDVI', '6_NDVI', '7_NDVI', '8_NDVI',  '9_NDVI', '10_NDVI', '11_NDVI']\n",
    "    print(newLabelsS2)    \n",
    "    csvDFS2 = csvDF.loc[:,newLabelsS2]\n",
    "    csvDFS2.to_csv(outCsvFile+\"_allNDVIdata.csv\")\n",
    "    csvDFS2=csvDFS2.groupby(Col).mean()\n",
    "    csvDFS2.to_csv(outCsvFile)\n",
    "    print(\"Mean monthy NDVIs of class \", Col, \" stored in \", outCsvFile)\n",
    "    \n",
    "    \n",
    "## function 10.5 takes as input the outputs of function 10 and finds the best month to distingished clasess of interest\n",
    "# inCsvFile+_allNDvidata.csv was exported in function 10.5 and used here\n",
    "def getMonthForBetterDistingishingClasses(inCsvFile,Col):\n",
    "    dfMean = pd.read_csv(inCsvFile, low_memory=False)\n",
    "    dfMean = dfMean.drop(dfMean[dfMean[Col] == 'mixed'].index)\n",
    "    dfMean['count'] = [0,0,0,0]\n",
    "    sqrDifs = np.zeros(12)\n",
    "    dfAll  = pd.read_csv(inCsvFile+\"_allNDVIdata.csv\", low_memory=False)\n",
    "    dfAll.set_index(Col, inplace=True)\n",
    "    #dfAll = dfAll.grouby(Col)\n",
    "    dfAll = dfAll.drop(dfMean[dfMean[Col] == 'mixed'].index)\n",
    "    print(dfMean)\n",
    "    print(\"sqrDifs = \",sqrDifs)\n",
    "    \n",
    "    \n",
    "        \n",
    "## function 11 takes as input the output of function 10 and creates a multiline graph for the mean NDVIs of each class\n",
    "def createGraphOfNDVIs(inCsvFile, Col, outImg):\n",
    "    df = pd.read_csv(inCsvFile, low_memory=False)\n",
    "    df.set_index(Col, inplace=True)\n",
    "    plt.figure(figsize=(14,6),  dpi=300)\n",
    "    df.T.plot(marker='o', linestyle='-')\n",
    "    plt.title(\"NDVI during 2019 of different forest types\")\n",
    "    plt.xlabel(\"Months\")\n",
    "    plt.ylabel(\"NDVI Values\")\n",
    "    plt.legend(title=\"Forest Types\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outImg)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    print(\"Image saved in \", outImg)\n",
    "    \n",
    "    \n",
    "## function 12 takes as input the output of function 9 and creates a multiline graph for the mean and std NDVIs of each class \n",
    "# # NOT WORKING\n",
    "def creatGraphOfNDVIsWithStd(inCsvFile,Col,outImg):\n",
    "    df = pd.read_csv(inCsvFile, low_memory=False)\n",
    "\n",
    "    # Set the 'Col' column as the index\n",
    "    df.set_index(Col, inplace=True)\n",
    "    \n",
    "\n",
    "    # Extract mean and std values\n",
    "    means = df.groupby(Col).mean()\n",
    "    stds = df.groupby(Col).std().fillna(df.groupby(Col).last())\n",
    "    \n",
    "    print (means)\n",
    "    print (stds)\n",
    "    print (\"HELLO WORLDS\")\n",
    "\n",
    "    # Plot the multiline graph with mean and std\n",
    "    plt.figure(figsize=(14, 6), dpi=300)\n",
    "    for label, mean_values, std_values in zip(means.index, means.values.T, stds.values.T):\n",
    "        plt.errorbar(x=means.columns, y=mean_values, yerr=std_values, marker='o', linestyle='-', label=label, alpha=0.7)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(\"Mean NDVI during 2019 of different forest types with Standard Deviation\")\n",
    "    plt.xlabel(\"Months\")\n",
    "    plt.ylabel(\"NDVI Values\")\n",
    "    plt.legend(title=\"Forest Types\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot to the specified output image file\n",
    "    plt.savefig(outImg)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Clear the plot\n",
    "    plt.clf()\n",
    "\n",
    "    print(\"Image saved in \", outImg)\n",
    "\n",
    "\n",
    "## function 13 takes as input a txt file and returns stats about execution time - file manually created by copying GEE output in Tasks\n",
    "# locations of files hardcoded because run only once\n",
    "def getExecutionTimeStatsforFile(inFile):\n",
    "  \n",
    "    file = open(inFile, 'r')\n",
    "    lines = file.readlines()\n",
    "    count = 0\n",
    "    allmins = []\n",
    "    S2_stdD_mins = []\n",
    "    S2_mean_mins = []\n",
    "    S1_stdD_mins = []\n",
    "    S1_mean_mins = []\n",
    "    invalidValues=0\n",
    "    for line in lines: \n",
    "        if count%2 != 0 : \n",
    "            line  = line.replace('m', '')\n",
    "            line  = line.replace('\\n', '')\n",
    "            try: \n",
    "                mins = int(line)\n",
    "                allmins = allmins + [mins]\n",
    "            except:\n",
    "                print (\"WARNING: one invalid value\")\n",
    "                invalidValues = invalidValues+1\n",
    "                allmins = allmins + [-1]\n",
    "        count = count + 1\n",
    "\n",
    "    allmins=np.array(allmins)\n",
    "    for x in range (0,len(allmins)):\n",
    "        if( x%4 == 0):\n",
    "            S2_stdD_mins = S2_stdD_mins + [allmins[x]]\n",
    "        if (x%4 == 1):\n",
    "            S2_mean_mins = S2_mean_mins + [allmins[x]]\n",
    "        if (x%4 == 2):\n",
    "            S1_stdD_mins = S1_stdD_mins + [allmins[x]]\n",
    "        if (x%4 == 3):\n",
    "            S1_mean_mins = S1_mean_mins + [allmins[x]]\n",
    "            \n",
    "    print( \"NAME, MEAN, STD, LEN, INVALID\")\n",
    "    \n",
    "    S2_stdD_minsInv = len(S2_stdD_mins)\n",
    "    S2_stdD_mins = [ v for v in S2_stdD_mins if v  >= 0 ]\n",
    "    S2_stdD_mins = np.array(S2_stdD_mins)\n",
    "    S2_stdD_minsInv = S2_stdD_minsInv-len(S2_stdD_mins)\n",
    "    print (\"S2_stdD_mins\", round(S2_stdD_mins.mean(),3), round(S2_stdD_mins.std(),3),len(S2_stdD_mins),S2_stdD_minsInv)\n",
    "    \n",
    "    S2_mean_minsInv = len(S2_mean_mins)\n",
    "    S2_mean_mins = [ v for v in S2_mean_mins if v  >= 0]\n",
    "    S2_mean_mins = np.array(S2_mean_mins)\n",
    "    S2_mean_minsInv = S2_mean_minsInv-len(S2_mean_mins)\n",
    "    print (\"S2_mean_mins\", round(S2_mean_mins.mean(),3), round(S2_mean_mins.std(),3),len(S2_mean_mins),S2_mean_minsInv)\n",
    "    \n",
    "    S1_stdD_minsInv = len(S1_stdD_mins)\n",
    "    S1_stdD_mins = [ v for v in S1_stdD_mins if v  >= 0]\n",
    "    S1_stdD_mins = np.array(S1_stdD_mins)\n",
    "    S1_stdD_minsInv = S1_stdD_minsInv-len(S1_stdD_mins)\n",
    "    print (\"S1_stdD_mins\", round(S1_stdD_mins.mean(),3), round(S1_stdD_mins.std(),3),len(S1_stdD_mins),S1_stdD_minsInv)\n",
    "\n",
    "    S1_mean_minsInv = len(S1_mean_mins)\n",
    "    S1_mean_mins = [ v for v in S1_mean_mins if v  >= 0]\n",
    "    S1_mean_mins = np.array(S1_mean_mins)\n",
    "    S1_mean_minsInv = S1_mean_minsInv-len(S1_mean_mins)\n",
    "    print (\"S1_mean_mins\", round(S1_mean_mins.mean(),3), round(S1_mean_mins.std(),3),len(S1_mean_mins),S1_mean_minsInv)\n",
    "\n",
    "    print (allmins.mean(),allmins.std(),len(allmins),invalidValues)\n",
    "    file.close()\n",
    "    \n",
    "\n",
    "def getExecutionTimeStats():\n",
    "    radius25  = \"/home/milto/Documents/fieldData/statsNImgs/Radius25.txt\" \n",
    "    radius50  = \"/home/milto/Documents/fieldData/statsNImgs/Radius50.txt\" \n",
    "    radius100 = \"/home/milto/Documents/fieldData/statsNImgs/Radius100.txt\" \n",
    "    print(\"******************\\nRADIUS 25\")\n",
    "    getExecutionTimeStatsforFile(radius25)\n",
    "    print(\"******************\\nRADIUS 50\")\n",
    "    getExecutionTimeStatsforFile(radius50)\n",
    "    print(\"******************\\nRADIUS 100\")\n",
    "    getExecutionTimeStatsforFile(radius100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
