{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MergedCsvs Exist\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "ERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 76\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mERROR: csv not sorted correctly or files are missing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m ListS1Mean\u001b[39m!=\u001b[39m[] \u001b[39mand\u001b[39;00m ListS2Mean\u001b[39m!=\u001b[39m[] \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(ListS2Mean)\u001b[39m!=\u001b[39m\u001b[39mlen\u001b[39m(ListS1Mean):\n\u001b[0;32m---> 76\u001b[0m    \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m ListS1StdD\u001b[39m!=\u001b[39m[] \u001b[39mand\u001b[39;00m ListS2StdD\u001b[39m!=\u001b[39m[] \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(ListS2StdD)\u001b[39m!=\u001b[39m\u001b[39mlen\u001b[39m(ListS1StdD):\n\u001b[1;32m     78\u001b[0m    \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: ERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet"
     ]
    }
   ],
   "source": [
    "# Please change this with the directory of the folder that contains the csv files downloaded\n",
    "# from your Drive\n",
    "nameOfCSVFolderDir = \"/home/milto/Documents/fieldData/gdrivefolder_Sentinel2\"\n",
    "nameOfCSVFolderDir = \"/home/milto/Documents/fieldData/gdrivefolderWORK\"\n",
    "# File exported that contains the column \"\" that will be used for merging the files\n",
    "fieldDataDir       =\"./.ipynb_checkpoints/FieldDataWithIdentifiers.csv\"\n",
    "samplingSizeFile   =\"./.ipynb_checkpoints/SamplingSize.txt\"\n",
    "samplingSize = 400\n",
    "\n",
    "# make tmp directories\n",
    "TmpDir = os.path.join(nameOfCSVFolderDir,\"TmpDir\")\n",
    "ResDir  = os.path.join(nameOfCSVFolderDir,\"MergedCsvs\")\n",
    "if os.path.isdir(TmpDir):\n",
    "    print (\"TmpDir Exist\")\n",
    "    shutil.rmtree(TmpDir)\n",
    "os.mkdir(TmpDir)\n",
    "if os.path.isdir(ResDir):\n",
    "    print (\"MergedCsvs Exist\")\n",
    "    shutil.rmtree(ResDir)\n",
    "os.mkdir(ResDir)\n",
    "\n",
    "# Read sampling rate\n",
    "try:\n",
    "  f = open(samplingSizeFile,\"r\")\n",
    "  samplingSize = int(f.readline())\n",
    "  f.close()\n",
    "except OSError:\n",
    "    print(\"ERROR:\", samplingSizeFile,\" does not exist. Setting sampling size to default = 400\")\n",
    "    samplingSize = 400\n",
    "\n",
    "\n",
    "    \n",
    "ListS1Mean=[]\n",
    "ListS2Mean=[]\n",
    "ListS1StdD=[]\n",
    "ListS2StdD=[]\n",
    "\n",
    "for file1 in glob.glob(nameOfCSVFolderDir+\"/*.csv\"):\n",
    "    S1Mean=\"S1_mean.csv\"\n",
    "    S2Mean=\"S2_mean.csv\"\n",
    "    S1StdD=\"S1_stdD.csv\"\n",
    "    S2StdD=\"S2_stdD.csv\"\n",
    "    if(len(file1)>11):\n",
    "        if   (file1[len(file1)-11:len(file1)]==S1Mean):\n",
    "            ListS1Mean=ListS1Mean+[file1]\n",
    "        elif (file1[len(file1)-11:len(file1)]==S2Mean):\n",
    "            ListS2Mean=ListS2Mean+[file1]\n",
    "        elif (file1[len(file1)-11:len(file1)]==S1StdD):\n",
    "            ListS1StdD=ListS1StdD+[file1]\n",
    "        elif (file1[len(file1)-11:len(file1)]==S2StdD):\n",
    "            ListS2StdD=ListS2StdD+[file1]\n",
    "        elif (file1[len(file1)-11:len(file1)]==\"tifiers.csv\"): #in case field data are added in the nameOfCSVFolderDir\n",
    "           print(file1 , \" is suspected to be the field data file\")\n",
    "        else :\n",
    "            print(\"WARNING: \", file1, \" is ignored since it is not recognised as an output of the system\")\n",
    "\n",
    "    #df = pd.read_csv(file)\n",
    "    #df = df.reindex(sorted(df.columns),axis=1)\n",
    "\n",
    "ListS1Mean.sort()\n",
    "ListS1StdD.sort()\n",
    "ListS2Mean.sort()\n",
    "ListS2StdD.sort()\n",
    "\n",
    "if(ListS1Mean!=[] and ListS1Mean[0][len(ListS1Mean[0])-33:len(ListS1Mean[0])-23]!=\"0000000000\"):\n",
    "    raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "if(ListS1StdD!=[] and ListS1StdD[0][len(ListS1StdD[0])-33:len(ListS1StdD[0])-23]!=\"0000000000\"):\n",
    "    raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "if(ListS2Mean!=[] and ListS2Mean[0][len(ListS2Mean[0])-33:len(ListS2Mean[0])-23]!=\"0000000000\"):\n",
    "    raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "if(ListS2StdD!=[] and ListS2StdD[0][len(ListS2StdD[0])-33:len(ListS2StdD[0])-23]!=\"0000000000\"):\n",
    "    raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "\n",
    "\n",
    "if ListS1Mean!=[] and ListS2Mean!=[] and len(ListS2Mean)!=len(ListS1Mean):\n",
    "   raise Exception (\"ERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet\")\n",
    "if ListS1StdD!=[] and ListS2StdD!=[] and len(ListS2StdD)!=len(ListS1StdD):\n",
    "   raise Exception (\"ERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstItem = None\n",
    "if(ListS1Mean!=[]):\n",
    "    firstItem=ListS1Mean[0]\n",
    "elif (ListS2Mean!=[]):\n",
    "    firstItem=ListS2Mean[0]\n",
    "else :\n",
    "    raise Exception (\"ERROR: no data found. Both Sentinel-1 and Sentinel-2 lists are empty\")\n",
    "\n",
    "tmpDF = pd.read_csv(firstItem)\n",
    "dfFieldData = pd.read_csv(fieldDataDir)\n",
    "lenOfFieldData = len(dfFieldData.index)\n",
    "currentMin = 0\n",
    "currentMax = samplingSize\n",
    "fileNames = firstItem[0:len(firstItem)-34] \n",
    "head, fileNames = os.path.split(fileNames)\n",
    "\n",
    "count = 0\n",
    "while currentMin<lenOfFieldData :\n",
    "    strCurrentMin = str(currentMin  ).rjust(10,'0')\n",
    "    strCurrentMax = str(currentMax-1).rjust(10,'0')\n",
    "    FilenamesWithSampling = fileNames+\"_\"+strCurrentMin+\"_\"+strCurrentMax\n",
    "    subsetFieldDF = dfFieldData.iloc[currentMin:currentMax]\n",
    "    dfMean=subsetFieldDF\n",
    "    dfStdD=subsetFieldDF\n",
    "    \n",
    "    if(count<len(ListS1Mean)):\n",
    "        tmpDF = pd.read_csv(ListS1Mean[count])\n",
    "        tmpDF = tmpDF.reindex(sorted(tmpDF.columns),axis=1)\n",
    "        dfMean = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "    if(count<len(ListS2Mean)):\n",
    "        tmpDF = pd.read_csv(ListS2Mean[count])\n",
    "        tmpDF = tmpDF.reindex(sorted(tmpDF.columns),axis=1)\n",
    "        dfMean = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "    \n",
    "    if(count<len(ListS1StdD)):\n",
    "        tmpDF = pd.read_csv(ListS1StdD[count])\n",
    "        tmpDF = tmpDF.reindex(sorted(tmpDF.columns),axis=1)\n",
    "        dfStdD = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "    if(count<len(ListS2StdD)):\n",
    "        tmpDF = pd.read_csv(ListS2StdD[count])\n",
    "        tmpDF = tmpDF.reindex(sorted(tmpDF.columns),axis=1)\n",
    "        dfStdD = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "    \n",
    "    dfMean.to_csv(TmpDir+\"/\"+FilenamesWithSampling+\"_Mean.csv\", index=False)\n",
    "    dfStdD.to_csv(TmpDir+\"/\"+FilenamesWithSampling+\"_StdD.csv\", index=False)\n",
    "    count = count+1\n",
    "    currentMin = currentMax\n",
    "    currentMax = currentMax + samplingSize\n",
    "\n",
    "ListMean=[]\n",
    "ListStdD=[]\n",
    "for file1 in glob.glob(TmpDir+\"/*.csv\"):\n",
    "    Mean=\"Mean.csv\"\n",
    "    StdD=\"StdD.csv\"\n",
    "    if(len(file1)>len(Mean)):\n",
    "        if   (file1[len(file1)-len(Mean):len(file1)]==Mean):\n",
    "            ListMean=ListMean+[file1]\n",
    "        elif (file1[len(file1)-len(Mean):len(file1)]==StdD):\n",
    "            ListStdD=ListStdD+[file1]\n",
    "ListMean.sort()\n",
    "ListStdD.sort()\n",
    "outMean = open(ResDir+\"/\"+fileNames+\"_mean.csv\",\"w\")\n",
    "outstdD = open(ResDir+\"/\"+fileNames+\"_stdD.csv\",\"w\")\n",
    "if(outstdD.closed or outMean.closed):\n",
    "    raise Exception (\"ERROR: Failed to create merged files. Possibly \", ResDir, \" was not created!\")\n",
    "\n",
    "count = 0\n",
    "fileNo = 0\n",
    "for file1 in ListMean:\n",
    "    fileNo = fileNo + 1\n",
    "    with open(file1) as file:\n",
    "        line = file.readline()\n",
    "        if fileNo == 1:\n",
    "            outMean.writelines(line) \n",
    "        count = 0\n",
    "        while(line):\n",
    "            if count == 0 :\n",
    "                count = 1\n",
    "                line = file.readline()   \n",
    "                continue\n",
    "            outMean.writelines(line) \n",
    "            line = file.readline()   \n",
    "    f.close()\n",
    "\n",
    "count = 0\n",
    "fileNo = 0\n",
    "for file1 in ListStdD:\n",
    "    fileNo = fileNo + 1\n",
    "    with open(file1) as file:\n",
    "        line = file.readline()\n",
    "        if fileNo == 1:\n",
    "            outstdD.writelines(line) \n",
    "        count = 0\n",
    "        while(line):\n",
    "            if count == 0 :\n",
    "                count = 1\n",
    "                line = file.readline()   \n",
    "                continue\n",
    "            outstdD.writelines(line) \n",
    "            line = file.readline()   \n",
    "    f.close()\n",
    "\n",
    "outMean.close()\n",
    "outstdD.close()\n",
    "\n",
    "shutil.rmtree(TmpDir)\n",
    "print(\"Results are stored in \", ResDir)\n",
    "print(\"   ***   EXIT   ***\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
