{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TmpDir Exist\n",
      "featurevectorWORK &&&&&&&&&&&&&&&&&&&&&&&\n",
      "featurevectorWORK_0000000000_0000000599\n",
      "0 600 1800\n",
      "featurevectorWORK_0000000600_0000001199\n",
      "600 1200 1800\n",
      "featurevectorWORK_0000001200_0000001799\n",
      "1200 1800 1800\n",
      "['/home/milto/Documents/fieldData/WORKS1/featurevectorWORK_0000000000_0000000599_S1_mean.csv', '/home/milto/Documents/fieldData/WORKS1/featurevectorWORK_0000000600_0000001199_S1_mean.csv']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "   ***   EXIT   ***\n"
     ]
    }
   ],
   "source": [
    "# Please change this with the directory of the folder that contains the csv files downloaded\n",
    "# from your Drive\n",
    "nameOfCSVFolderDir = \"/home/milto/Documents/fieldData/gdrivefolder_Sentinel2\"\n",
    "nameOfCSVFolderDir = \"/home/milto/Documents/fieldData/WORKS1\"\n",
    "# File exported that contains the column \"\" that will be used for merging the files\n",
    "fieldDataDir       =\"./.ipynb_checkpoints/FieldDataWithIdentifiers.csv\"\n",
    "samplingSizeFile   =\"./.ipynb_checkpoints/SamplingSize.txt\"\n",
    "samplingSize = 400\n",
    "\n",
    "# make tmp directories\n",
    "TmpDir = os.path.join(nameOfCSVFolderDir,\"TmpDir\")\n",
    "S2DirMean = os.path.join(nameOfCSVFolderDir,\"S2Mean\")\n",
    "S1DirStd  = os.path.join(nameOfCSVFolderDir,\"S1Std\" )\n",
    "S2DirStd  = os.path.join(nameOfCSVFolderDir,\"S2Std\" )\n",
    "\n",
    "# Read sampling rate\n",
    "try:\n",
    "  f = open(samplingSizeFile,\"r\")\n",
    "  samplingSize = int(f.readline())\n",
    "  f.close()\n",
    "except OSError:\n",
    "    print(\"ERROR:\", samplingSizeFile,\" does not exist. Setting sampling size to default = 400\")\n",
    "    samplingSize = 400\n",
    "\n",
    "if os.path.isdir(TmpDir):\n",
    "    print (\"TmpDir Exist\")\n",
    "    shutil.rmtree(TmpDir)\n",
    "\n",
    "\n",
    "os.mkdir(TmpDir)\n",
    "    \n",
    "ListS1Mean=[]\n",
    "ListS2Mean=[]\n",
    "ListS1StdD=[]\n",
    "ListS2StdD=[]\n",
    "\n",
    "for file in glob.glob(nameOfCSVFolderDir+\"/*.csv\"):\n",
    "    S1Mean=\"S1_mean.csv\"\n",
    "    S2Mean=\"S2_mean.csv\"\n",
    "    S1StdD=\"S1_stdD.csv\"\n",
    "    S2StdD=\"S2_stdD.csv\"\n",
    "    if(len(file)>11):\n",
    "        if   (file[len(file)-11:len(file)]==S1Mean):\n",
    "            ListS1Mean=ListS1Mean+[file]\n",
    "        elif (file[len(file)-11:len(file)]==S2Mean):\n",
    "            ListS2Mean=ListS2Mean+[file]\n",
    "        elif (file[len(file)-11:len(file)]==S1StdD):\n",
    "            ListS1StdD=ListS1StdD+[file]\n",
    "        elif (file[len(file)-11:len(file)]==S2StdD):\n",
    "            ListS2StdD=ListS2StdD+[file]\n",
    "        elif (file[len(file)-11:len(file)]==\"tifiers.csv\"): #in case field data are added in the nameOfCSVFolderDir\n",
    "           print(file , \" is suspected to be the field data file\")\n",
    "        else :\n",
    "            print(\"WARNING: \", file, \" is ignored since it is not recognised as an output of the system\")\n",
    "\n",
    "    #df = pd.read_csv(file)\n",
    "    #df = df.reindex(sorted(df.columns),axis=1)\n",
    "\n",
    "ListS1Mean.sort()\n",
    "ListS1StdD.sort()\n",
    "ListS2Mean.sort()\n",
    "ListS2StdD.sort()\n",
    "\n",
    "if(ListS1Mean!=[] and ListS1Mean[0][len(ListS1Mean[0])-33:len(ListS1Mean[0])-23]!=\"0000000000\"):\n",
    "    raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "if(ListS1StdD!=[] and ListS1StdD[0][len(ListS1StdD[0])-33:len(ListS1StdD[0])-23]!=\"0000000000\"):\n",
    "    raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "if(ListS2Mean!=[] and ListS2Mean[0][len(ListS2Mean[0])-33:len(ListS2Mean[0])-23]!=\"0000000000\"):\n",
    "    raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "if(ListS2StdD!=[] and ListS2StdD[0][len(ListS2StdD[0])-33:len(ListS2StdD[0])-23]!=\"0000000000\"):\n",
    "    raise Exception(\"ERROR: csv not sorted correctly or files are missing\")\n",
    "\n",
    "if ListS1Mean!=[] and ListS2Mean!=[] and len(ListS2Mean)!=len(ListS1Mean):\n",
    "   raise Exception(\"ERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet\")\n",
    "if ListS1StdD!=[] and ListS2StdD!=[] and len(ListS2StdD)!=len(ListS1StdD):\n",
    "   raise Exception(\"ERROR: if both Sentinel 1 and Sentinel 2 data were loaded then equal number of csv files should have existed - maybe GEE processing have not finished yet\")\n",
    "\n",
    "\n",
    "\n",
    "firstItem = None\n",
    "if(ListS1Mean!=[]):\n",
    "    firstItem=ListS1Mean[0]\n",
    "elif (ListS2Mean!=[]):\n",
    "    firstItem=ListS2Mean[0]\n",
    "else :\n",
    "    raise Exception (\"ERROR: no data found. Both Sentinel-1 and Sentinel-2 lists are empty\")\n",
    "\n",
    "tmpDF = pd.read_csv(firstItem)\n",
    "dfFieldData = pd.read_csv(fieldDataDir)\n",
    "lenOfFieldData = len(dfFieldData.index)\n",
    "currentMin = 0\n",
    "currentMax = samplingSize\n",
    "fileNames = firstItem[0:len(firstItem)-34] \n",
    "head, fileNames = os.path.split(fileNames)\n",
    "print(fileNames, \"&&&&&&&&&&&&&&&&&&&&&&&\")\n",
    "\n",
    "\n",
    "count = 0\n",
    "while currentMin<lenOfFieldData :\n",
    "    strCurrentMin = str(currentMin  ).rjust(10,'0')\n",
    "    strCurrentMax = str(currentMax-1).rjust(10,'0')\n",
    "    FilenamesWithSampling = fileNames+\"_\"+strCurrentMin+\"_\"+strCurrentMax\n",
    "    print(FilenamesWithSampling)\n",
    "  \n",
    "\n",
    "    print(currentMin,currentMax,lenOfFieldData)\n",
    "    currentMin = currentMax\n",
    "    currentMax = currentMax + samplingSize\n",
    "    subsetFieldDF = dfFieldData.iloc[currentMin:currentMax]\n",
    "    dfMean=subsetFieldDF\n",
    "    dfStdD=subsetFieldDF\n",
    "    \n",
    "    if(count<len(ListS1Mean)):\n",
    "        tmpDF = pd.read_csv(ListS1Mean[count])\n",
    "        dfMean = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "        print(\"MERGING FIELD DATA WITH S1 MEAN\")\n",
    "    if(count<len(ListS2Mean)):\n",
    "        tmpDF = pd.read_csv(ListS2Mean[count])\n",
    "        dfMean = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "    \n",
    "    if(count<len(ListS1StdD)):\n",
    "        tmpDF = pd.read_csv(ListS1StdD[count])\n",
    "        dfStdD = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "    if(count<len(ListS2StdD)):\n",
    "        tmpDF = pd.read_csv(ListS2StdD[count])\n",
    "        dfStdD = pd.merge(dfMean,tmpDF,on=\"indexField\",how='outer')\n",
    "    \n",
    "    dfMean.to_csv(TmpDir+\"/\"+FilenamesWithSampling+\"_Mean.csv\", index=False)\n",
    "\n",
    "    dfStdD.to_csv(TmpDir+\"/\"+FilenamesWithSampling+\"_dfStdD.csv\", index=False)\n",
    "\n",
    "    count = count+1\n",
    "    #break\n",
    "\n",
    "print(ListS1Mean)\n",
    "print(ListS1StdD)\n",
    "print(ListS2Mean)\n",
    "print(ListS2StdD)\n",
    "\n",
    "\n",
    "    #print(df)\n",
    "\n",
    "#shutil.rmtree(TmpDir)\n",
    "\n",
    "print(\"   ***   EXIT   ***\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
